wordcloud(table_words[,1],table_words[,2],random.order = F)
library(wordcloud)
library(tidyRSS)
library(XML)
library(RCurl)
library(jiebaR)
library(stringr)
library(plyr)
library(wordcloud)
library(wordcloud2)
library(tidyRSS)
rss_url <- 'https://udn.com/rssfeed/news/2/6649?ch=news'
rss <- tidyRSS::tidyfeed(feed = rss_url)
rss$feed_title# RSS標題
rss$feed_link# RSS超連結
rss$feed_description# 說明
rss$feed_language# 語系
rss$item_title# 文章標題
rss$item_link # 文章超連結
rss <- tidyRSS::tidyfeed(feed = rss_url)
ua <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36"
myHttpHeader <- c( "User-Agent"=ua,
"accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3",
"accept-encoding: gzip, deflate, br",
"accept-language: zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6",
"referer: https://udn.com/news/breaknews/1",
"upgrade-insecure-requests: 1",
"user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36"
)
curl_handle <- getCurlHandle()
curlSetOpt(.opts=list(myHttpHeader),cookiejar="cookies.txt",  useragent = ua, followlocation = TRUE, curl=curl_handle,verbose=TRUE)
data <- list()
i <- 1
for( link in rss$item_link){
print(paste(i,link,sep=","))
html_doc<- htmlParse(getURL(link, curl = curl_handle), encoding = "UTF-8")
article_item<- xpathSApply(html_doc, '//*[@id="story_body_content"]//p', xmlValue)
article_item<- gsub("\\s+", "", article_item)
article_item<- gsub(" $", "", article_item)
article_item<- paste(article_item,collapse = "")
data[i] <- article_item
i <- i+1
t <- sample(2:5,1)
Sys.sleep(t)
}
data <- unlist(data)
cutter=worker(user = "E:/R/0714need.utf8",stop_word="E:/R/0714rubbish.utf8")
seq_words <- cutter <= data
library(plyr)
table_words <- count(seq_words)
library(wordcloud)
wordcloud(table_words[,1],table_words[,2],random.order = F)
library(RCurl)
set.seed(123)
x->rnorm(100,mean = 20,sd=5)
set.seed(123)
x->rnorm(100,mean = 20,sd=5)
hist(x)
x<-rnorm(100,mean = 20,sd=5)
hist(x)
set.seed(123)
x<-rnorm(100,mean = 20,sd=5)
hist(x)
summary(x)
x<-rnorm(10000,mean = 20,sd=5)
summary(x)
hist(x)
x<-rnorm(100,mean = 20,sd=5)
hist(x)
x<-rnorm(10000,mean = 20,sd=5)
hist(x)
summary(x)
x<-rnorm(60000,1,6) #min & max
set.seed(123)
x<-rnorm(60000,1,6) #min & max
hist(x) #normal
summary(x)
hist(x) #normal
data(iris)
shapiro.test(iris$Petal.Length)
data(iris)
shapiro.test(iris$Petal.Length)
hist(iris$Petal.Length,prob=T)
Petal.Length
hist(iris$Petal.Length,prob=T)
curve(dnorm(x,mean(iris$Petal.Length),sd(iris$Petal.Length)),col='red',add=T)
#H0為常態分布；H1不為常態分佈
#p-value>0.05表示"不"顯著，接受虛無假設H0，沒有足夠證據證明不是Normal
shapiro.test(iris$Sepal.Width)
hist(iris$Sepal.Width,prob=T)
curve(dnorm(x,mean(iris$Petal.Width),sd(iris$Petal.Width)),col='red',add=T)
shapiro.test(iris$Petal.Length)
hist(iris$Petal.Length,prob=T)
curve(dnorm(x,mean(iris$Petal.Length),sd(iris$Petal.Length)),col='red',add=T)
#H0為常態分布；H1不為常態分佈
#p-value>0.05表示"不"顯著，接受虛無假設H0，沒有足夠證據證明不是Normal
shapiro.test(iris$Sepal.Width)
hist(iris$Sepal.Width,prob=T)
curve(dnorm(x,mean(iris$Petal.Width),sd(iris$Petal.Width)),col='red',add=T)
install.packages('C50')
library(C50)
?(churn)
data(churn)
str(churnTrain)
#mean=160
#H0白天通話平均==160通；H1白天通話平均!=160通
#顯著水準alpha=0.05
t.test(churnTrain$total_day_calls,mu=160,alternative = 'two.sided')
#var.test(x,y,ratio = 1,alternative = c('two.sided','less','greater'),conf.level = 0.95,...)
#想知道area_code_408與area_code_415白天通話平均通數是否顯著相同
# H0: 變異數total_day_calls_408/變異數total_day_calls_415  = 1
# H1: 變異數total_day_calls_408/變異數total_day_calls_415 != 1
# 顯著水準 alpha = 0.05
library(C50)
data(churn)
var.test( churnTrain$total_day_calls[churnTrain$area_code=='area_code_408' ], churnTrain$total_day_calls[churnTrain$area_code=='area_code_415' ])
#想知道area_code_408與area_code_415白天通話平均通數是否顯著相同
# H0: 平均數total_day_calls_408 – 平均數total_day_calls_415 = 0
# H1: 平均數total_day_calls_408 – 平均數total_day_calls_415 != 0
# 顯著水準 alpha = 0.05
t.test(churnTrain$total_day_calls[churnTrain$area_code=='area_code_408' ], churnTrain$total_day_calls[churnTrain$area_code=='area_code_415' ], mu=0, var.equal=T)
#想知道CA區與VT區夜間通話平均通數是否顯著相同
## 先進行變異數檢定
# H0:變異數total_night_calls_CA/變異數total_night_calls_VT = 1
# H1:變異數total_night_calls_CA/變異數total_night_calls_VT != 1
# 顯著水準 alpha = 0.05
var.test(churnTrain$total_night_calls[churnTrain$state=='CA' ], churnTrain$total_night_calls[churnTrain$state=='VT'])
# 想知道新的促銷對刷卡金額是否有影響
# H0:平均數刷卡金額_促銷之前– 平均數刷卡金額_促銷之後 = 0
# H1:平均數刷卡金額_促銷之前– 平均數刷卡金額_促銷之後 != 0
# 顯著水準 alpha = 0.05
Crd_amt_before <- rnorm(10000,mean=4032,sd=570)
Crd_amt_after <- rnorm(10000,mean=5661,sd=690)
t.test(Crd_amt_before, Crd_amt_after, mu=0, paired=T, var.equal=F)
# 想知道性別與客戶流失是否相關
## 兩組樣本必須是類別資料
# H0:兩因素無關係
# H1:兩因素有關係
# 顯著水準 alpha = 0.05
dt <- matrix(c(38,45,100,77),ncol=2)
chisq.test(dt)
# 想知道性別與客戶流失是否相關
## 兩組樣本必須是類別資料
# H0:兩因素無關係
# H1:兩因素有關係
# 顯著水準 alpha = 0.05
dt <- matrix(c(38,45,100,77),ncol=2)
chisq.test(dt)
# 想知道客戶夜間通話次數與日間通話次數的相關程度
# 兩組樣本必須是數值資料
# H0:兩因素相關係數= 0
# H1:兩因素相關係數!=0
# 顯著水準alpha=0.05
cor(churnTrain$total_night_calls, churnTrain$total_day_calls)
cor.test(churnTrain$total_night_calls, churnTrain$total_day_calls)
# 想知道不同教育程度與每日平均上網時數是否有差異
# H0:uGo to Internet_高中 = uGo to Internet_大學 = uGo to Internet_研究所
# H1:至少有兩組平均上網時數有差異
# 顯著水準alpha=0.05
df <- data.frame( group = c(rep(1, 20), rep(2, 20), rep(3,20) ), #1:高中, 2:大學, 3:研究所
GoInternet = floor(runif(n = 60, min = 1, max = 10)) )
lm_df <- lm(GoInternet~group, data=df)
anova(lm_df)
lm_df<-lm(group~Golnternet,data=df)
# 另外一個函數aov
lm_df <- lm(group~GoInternet, data=df)
anova(lm_df)
a <- aov(lm_df)
summary(a)
boxplot(GoInternet~group, data=df)
#多重比較找出差異項目
fit <- aov(GoInternet~factor(group), data=df)
TukeyHSD(fit)
plot(TukeyHSD(fit))
# 自行產生藥劑量與感冒痊癒天數資料
x <- c(3,3,4,3,6,8,8,9) #藥劑量
y <- c(22,25,18,20,16,9,12,5) #感冒痊癒天數
New_x <- data.frame(x=5) #預測當x=5時的痊癒天數
# 建立一個線性迴歸模
Train <- data.frame(x = x, y = y)
lmTrain <- lm(formula = y ~ x, data = Train)
predicted <- predict(lmTrain , newdata = New_x) #預測當x=5時的痊癒天數
# 模型摘
summary(lmTrain )
# 作圖
plot(y~x , main = "依藥劑量預測痊癒天數", xlab = "藥劑量", ylab = "感冒痊癒天數", family = "STHeiti")
points(x = New_x, y = predicted, col="green", cex = 2, pch = 16)
abline(reg = lmTrain$coefficients, col = "red", lwd = 1) #函數繪製輔助線 >
# 模型摘
summary(lmTrain )
# 作圖
plot(y~x , main = "依藥劑量預測痊癒天數", xlab = "藥劑量", ylab = "感冒痊癒天數", family = "STHeiti")
points(x = New_x, y = predicted, col="green", cex = 2, pch = 16)
abline(reg = lmTrain$coefficients, col = "red", lwd = 1) #函數繪製輔助線 >
abline(reg = lmTrain$coefficients, col = "red", lwd = 1) #函數繪製輔助線
# 作圖
plot(y~x , main = "依藥劑量預測痊癒天數", xlab = "藥劑量", ylab = "感冒痊癒天數", family = "STHeiti")
points(x = New_x, y = predicted, col="green", cex = 2, pch = 16)
# 模型摘
summary(lmTrain )
# 作圖
plot(y~x , main = "依藥劑量預測痊癒天數", xlab = "藥劑量", ylab = "感冒痊癒天數", family = "STHeiti")
points(x = New_x, y = predicted, col="green", cex = 2, pch = 16)
abline(reg = lmTrain$coefficients, col = "red", lwd = 1) #函數繪製輔助線
# 模型摘
summary(lmTrain )
# 模型摘
summary(lmTrain )
29.8043-2.5326*5
# 自行產生藥劑量、平均每日睡眠時間與感冒痊癒天數資料
x1 <- c(3,3,4,3,6,8,8,9) #藥劑量
x2 <- c(3,1,6,4,9,10,8,11) #平均每日睡眠時數
y <- c(22,25,18,20,16,9,12,5) #感冒痊癒天數
#新患者資料
New_x1 <- 5 #預測當x=5時的痊癒天數
New_x2 <- 7 #每日睡眠時數
New_data <- data.frame(x1 = 5, x2=7)
# 建立一個線性迴歸模型
Train <- data.frame(x1 = x1, x2=x2, y = y)
lmTrain <- lm(formula = y ~., data = Train)
#預測新患者感冒痊癒天數
predicted <- predict(lmTrain , newdata = New_data)
predicted
# 模型摘要
summary(lmTrain )
#絕對百分比誤差MAPE=(|樣本實際值-樣本預測值|/樣本實際)後的平均值
#MAPE<10%         good
#10%<=MAPE<=20%   ok
#MAPE>=20%        bad
y_hat=predict(lmTrain , newdata = data.frame(x=x))
train.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(train)=",train.MAPE*100,"%\n")
#讀入CSV檔
babyData=read.table("babies.csv",header=T,sep = ",")
#讀入CSV檔
setwd('E:/DM/work/0727')
babyData=read.table("babies.csv",header=T,sep = ",")
#排除有遺漏值的資料列
babyData=na.exclude(babyData)
#訓練樣本70%與測試樣本30%
n=0.3*nrow(babyData)
test.index=sample(1:nrow(babyData),n)
Train=babyData [-test.index,]
Test=babyData[test.index,]
#確認訓練樣本與測試樣本分不一致
par(mfrow=c(1,2)) #讓R的繪圖視窗切割成1 X 2 的方塊
hist(Train$bwt)
hist(Test$bwt)
#建模
install.packages("rpart")
library(rpart)
install.packages("rpart")
install.packages("rpart")
library(rpart)
baby.tree=rpart(bwt~. ,data=Train) #使用CART分類回歸樹演算法
baby.tree > plot(baby.tree)
hist(Train$bwt)
hist(Test$bwt)
#確認訓練樣本與測試樣本分不一致
par(mfrow=c(1,2)) #讓R的繪圖視窗切割成1 X 2 的方塊
hist(Train$bwt)
hist(Test$bwt)
#建模
install.packages("rpart")
library(rpart)
baby.tree=rpart(bwt~. ,data=Train) #使用CART分類回歸樹演算法
baby.tree > plot(baby.tree)
text(baby.tree , cex=.8)
install.packages("rpart")
install.packages("rpart")
baby.tree=rpart(bwt~. ,data=Train) #使用CART分類回歸樹演算法
baby.tree > plot(baby.tree)
text(baby.tree , cex=.8)
baby.tree
plot(baby.tree)
text(baby.tree , cex=.8)
#MAPE
#變數重要程度
baby.tree%variable.importance
#MAPE
#變數重要程度
baby.tree$variable.importance
#MAPE
y=babyData$bwt[-test.index]
y_hat=predict(baby.tree,newdata=Train, type="vector")
train.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(train)=",train.MAPE*100,"%\n")
y=babyData$bwt[test.index]
y_hat=predict(baby.tree,newdata=Test, type="vector")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
setwd('E:/DM/work/0727')
babyData=read.table("babies.csv",header=T,sep = ",")
#排除有遺漏值的資料列
babyData=na.exclude(babyData)
#訓練樣本70%與測試樣本30%
n=0.4*nrow(babyData)
test.index=sample(1:nrow(babyData),n)
Train=babyData [-test.index,] #'-'代表刪除[]內
Test=babyData[test.index,] #在','代表取的筆數；','後代表欄位，空白代表全取
#建模
lmTrain <- lm(formula = bwt ~., data = Train)
summary(lmTrain)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y) cat("MAPE(test)=",test.MAPE*100,"%\n")
test.MAPE=mean(abs(y-y_hat)/y)cat("MAPE(test)=",test.MAPE*100,"%\n")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
#再次建模，去掉age與weight
lmTrain_1 <- lm(formula = bwt ~ gestation+parity+height+smoke, data = Train)
summary(lmTrain_1)
#再次建模，去掉age與weight
lmTrain_1 <- lm(formula = bwt ~ gestation+parity+height+smoke, data = Train)
summary(lmTrain_1)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain_1,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
setwd('E:/DM/work/0727')
babyData=read.table("babies.csv",header=T,sep = ",")
#排除有遺漏值的資料列
babyData=na.exclude(babyData)
#訓練樣本70%與測試樣本30%
n=0.4*nrow(babyData)
test.index=sample(1:nrow(babyData),n)
Train=babyData [-test.index,] #'-'代表刪除[]內
Test=babyData[test.index,] #在','代表取的筆數；','後代表欄位，空白代表全取
#建模
lmTrain <- lm(formula = bwt ~., data = Train)
summary(lmTrain)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
#再次建模，去掉age與weight
lmTrain_1 <- lm(formula = bwt ~ gestation+parity+height+smoke, data = Train)
summary(lmTrain_1)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain_1,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
setwd('E:/DM/work/0727')
babyData=read.table("babies.csv",header=T,sep = ",")
#排除有遺漏值的資料列
babyData=na.exclude(babyData)
#訓練樣本70%與測試樣本30%
n=0.4*nrow(babyData)
test.index=sample(1:nrow(babyData),n)
Train=babyData [-test.index,] #'-'代表刪除[]內
Test=babyData[test.index,] #在','代表取的筆數；','後代表欄位，空白代表全取
#建模
lmTrain <- lm(formula = bwt ~., data = Train)
summary(lmTrain)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
#再次建模，去掉age與weight
lmTrain_1 <- lm(formula = bwt ~ gestation+parity+height+smoke, data = Train)
summary(lmTrain_1)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain_1,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
setwd('E:/DM/work/0727')
babyData=read.table("babies.csv",header=T,sep = ",")
#排除有遺漏值的資料列
babyData=na.exclude(babyData)
#訓練樣本70%與測試樣本30%
n=0.4*nrow(babyData)
test.index=sample(1:nrow(babyData),n)
Train=babyData [-test.index,] #'-'代表刪除[]內
Test=babyData[test.index,] #在','代表取的筆數；','後代表欄位，空白代表全取
#建模
lmTrain <- lm(formula = bwt ~., data = Train)
summary(lmTrain)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
#再次建模，去掉age與weight
lmTrain_1 <- lm(formula = bwt ~ gestation+parity+height+smoke, data = Train)
summary(lmTrain_1)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain_1,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
summary(lmTrain_1)
summary(lmTrain_1)
setwd('E:/DM/work/0727')
babyData=read.table("babies.csv",header=T,sep = ",")
#排除有遺漏值的資料列
babyData=na.exclude(babyData)
#訓練樣本70%與測試樣本30%
n=0.4*nrow(babyData)
test.index=sample(1:nrow(babyData),n)
Train=babyData [-test.index,] #'-'代表刪除[]內
Test=babyData[test.index,] #在','代表取的筆數；','後代表欄位，空白代表全取
#建模
lmTrain <- lm(formula = bwt ~., data = Train)
summary(lmTrain)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
#再次建模，去掉age與weight
lmTrain_1 <- lm(formula = bwt ~ gestation+parity+height+smoke, data = Train)
summary(lmTrain_1)
# 數值變數預測效果評估: MAPE(Mean Absolute Percentage Error)
y=babyData$bwt[test.index]
y_hat=predict(lmTrain_1,newdata=Test, type="response")
test.MAPE=mean(abs(y-y_hat)/y)
cat("MAPE(test)=",test.MAPE*100,"%\n")
install.packages("C50")
library(C50)
pca_Traindt<-princomp(data,cor=T)
install.packages("C50")
install.packages("C50")
library(C50)
data(churn)
data <- churnTrain[,c(-1,-3,-4,-5,-20)] #不要第1, 3, 4, 5, 20欄
pca_Traindt <- princomp( data , cor=T) #cor=T單位不同
summary(pca_Traindt)
library(rpart).
library(rpart)
screeplot(pca_Traindt,type="lines") #繪製陡坡圖
print(pca_Traindt$loadings, digits = 8, cutoff=0)
p<-predict(pca_Traindt) #算出主成分
head(p,5)
p[,c(1:7)]
p[,c(1:7)]
head(p,5)
p[,c(1:7)]
x=1
x
x
#檢視各因子可解釋的變異
print(pca_Traindt$loadings, digits = 8, cutoff=0)
#檢視各因子可解釋的變異
print(pca_Traindt$loadings, digits = 8, cutoff=0)
#檢視各因子可解釋的變異
print(pca_Traindt$loadings, digits = 8, cutoff=0)
#檢視各因子可解釋的變異
print(pca_Traindt$loadings,  cutoff=0)
source('E:/DM/work/Unit4/KNN.R', encoding = 'UTF-8', echo=TRUE)
install.packages('class')
library(class)
data(iris)
#(1)設定亂數種子
set.seed(123)
#(2)取得資料筆數
n <- nrow(iris)
#(3)取得訓練樣本數的index，70%建模，30%驗證
train_idx <- sample(seq_len(n), size = round(0.7 * n))
#(4)產出訓練資料與測試資料 > traindata <- iris[train_idx,] > testdata <- iris[ - train_idx,]
train_y <- traindata[,5]
test_y <- testdata[,5]
#(4)產出訓練資料與測試資料
traindata <- iris[train_idx,] > testdata <- iris[ - train_idx,]
#(4)產出訓練資料與測試資料
traindata <- iris[train_idx,]
testdata <- iris[ - train_idx,]
train_y <- traindata[,5]
test_y <- testdata[,5]
#(5)設定K，K通常可以設定為資料筆數的平方根
k_set <- as.integer(sqrt(n))
data(iris)
#(1)設定亂數種子
set.seed(123)
#(2)取得資料筆數
n <- nrow(iris)
#(3)取得訓練樣本數的index，60%建模，40%驗證
train_idx <- sample(seq_len(n), size = round(0.6 * n))
#(4)產出訓練資料與測試資料
traindata <- iris[train_idx,]
testdata <- iris[ - train_idx,]
train_y <- traindata[,5]
test_y <- testdata[,5]
#(5)設定K，K通常可以設定為資料筆數的平方根
k_set <- as.integer(sqrt(n))
#(6)建立模型
pred <- knn(train = traindata[-5], test = testdata[-5], cl = train_y, k = k_set)
#(7) 混淆矩陣計算準確度
message("準確度：",sum(diag(table(test_y,pred))) / sum(table(test_y,pred)) *100,"%")
#(3)取得訓練樣本數的index，70%建模，30%驗證
train_idx <- sample(seq_len(n), size = round(0.7 * n))
#(4)產出訓練資料與測試資料
traindata <- iris[train_idx,]
testdata <- iris[ - train_idx,]
train_y <- traindata[,5]
test_y <- testdata[,5]
#(5)設定K，K通常可以設定為資料筆數的平方根
k_set <- as.integer(sqrt(n))
#(6)建立模型
pred <- knn(train = traindata[-5], test = testdata[-5], cl = train_y, k = k_set)
#(7) 混淆矩陣計算準確度
message("準確度：",sum(diag(table(test_y,pred))) / sum(table(test_y,pred)) *100,"%")
